{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 2_Callowhill-St-12th-St.xls\n"
     ]
    }
   ],
   "source": [
    "from tmc_summarizer import TMC_File \n",
    "tmc = TMC_File('/mnt/g/My Drive/TMC2/2_Callowhill-St-12th-St.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08:15 to 09:15'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmc.meta['am_peak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EB U', 'EB Left', 'EB Thru', 'EB Right', 'EB Xwalk Xings', 'WB U',\n",
       "       'WB Left', 'WB Thru', 'WB Right', 'WB Xwalk Xings', 'NB U', 'NB Left',\n",
       "       'NB Thru', 'NB Right', 'NB Xwalk Xings', 'SB U', 'SB Left', 'SB Thru',\n",
       "       'SB Right', 'SB Xwalk Xings', 'total_15_min', 'total_hourly'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmc.df_total.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "tmc_summarizer.summarize.py\n",
    "---------------------------\n",
    "\n",
    "This module automates the import of\n",
    "all .xls files in a given folder with\n",
    "``write_summary_file()`` as long as\n",
    "they meet the criteria defined within\n",
    "``files_to_process()``\n",
    "\n",
    "Usage\n",
    "-----\n",
    "\n",
    "    In [1]: from tmc_summarizer import write_summary_file\n",
    "\n",
    "    In [2]: write_summary_file('my/raw/folder', 'my/output/folder')\n",
    "\n",
    "    Out [2]:\n",
    "        Reading 150315_US13BristolPikeBathSt.xls\n",
    "        Reading ...\n",
    "        Reading 150309_US13BristolPike_and_WalnutAve.xls\n",
    "\n",
    "        -> Wrote TMC summary to data/cleaned/TMC Summary 2020-07-01 21-22-49.xlsx\n",
    "        -> Runtime: 0:00:03.622940\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "from tmc_summarizer.data_model import TMC_File, geocode_tmc\n",
    "from tmc_summarizer.helpers import zip_files\n",
    "import statistics\n",
    "\n",
    "\n",
    "def files_to_process(folder: Path) -> list:\n",
    "    \"\"\"Make a list of files to process. File names must meet\n",
    "    the following criteria:\n",
    "        - file ends in ``.xls``\n",
    "        - filename has at least 1 underscore\n",
    "        - text before the first underscore can be converted to an integer\n",
    "\n",
    "    :param folder: folder where files are stored\n",
    "    :type folder: Path\n",
    "    :return: list of files that meet criteria\n",
    "    :rtype: list\n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of all .xls files in the folder\n",
    "    files = list(folder.glob(\"**/*.xls\"))\n",
    "\n",
    "    # Remove any files that don't have proper naming conventions\n",
    "    for f in files:\n",
    "\n",
    "        # Make sure there is at least 1 underscore\n",
    "        if \"_\" not in str(f.name):\n",
    "            print(f\"No underscores, skipping {f.name}\")\n",
    "            files.remove(f)\n",
    "\n",
    "        # Make sure that the Location ID is an integer\n",
    "        parts = str(f.name).split(\"_\")\n",
    "\n",
    "        try:\n",
    "            _ = int(parts[0])\n",
    "\n",
    "        except ValueError:\n",
    "            print(f\"Bad Location ID, skipping {f.name}\")\n",
    "            files.remove(f)\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_network_peak_hour_df(df: pd.DataFrame, start, end):\n",
    "    \"\"\"Creates a network peak hour summary df.\n",
    "    Should only be run AFTER all TMCs are created,\n",
    "    as TMCs are created by intersection peaks, then compiled to network\"\"\"\n",
    "    try:\n",
    "        df.index = df.index.time\n",
    "    except:\n",
    "        df.index = df.index\n",
    "    # Filter the total dataframe by the start/end times\n",
    "    df_peak = df.loc[(df.index >= start) & (df.index < end)]\n",
    "\n",
    "    # Delete the \"total_hourly\" column as it makes no sense to sum\n",
    "    del df_peak[\"total_hourly\"]\n",
    "\n",
    "    return df_peak.sum().to_frame().T\n",
    "\n",
    "\n",
    "def get_df_peak(df: pd.DataFrame, start, end):\n",
    "    try:\n",
    "        df.index = df.index.time\n",
    "    except:\n",
    "        df.index = df.index\n",
    "    # Filter the total dataframe by the start/end times\n",
    "    df_peak = df.loc[(df.index >= start) & (df.index < end)]\n",
    "    return df_peak\n",
    "\n",
    "\n",
    "def df_network_peak_hour_heavy_pct(\n",
    "    start, end, df_total: pd.DataFrame, df_cars: pd.DataFrame\n",
    "):\n",
    "    cars_copy = df_cars.rename(\n",
    "        columns={\n",
    "            \"EB Peds Xwalk\": \"EB Xwalk Xings\",\n",
    "            \"WB Peds Xwalk\": \"WB Xwalk Xings\",\n",
    "            \"NB Peds Xwalk\": \"NB Xwalk Xings\",\n",
    "            \"SB Peds Xwalk\": \"SB Xwalk Xings\",\n",
    "        }\n",
    "    )\n",
    "    peak_total = get_network_peak_hour_df(df_total, start, end)\n",
    "    peak_cars = get_network_peak_hour_df(cars_copy, start, end)\n",
    "    return (1 - peak_cars / peak_total) * 100\n",
    "\n",
    "\n",
    "def network_peak_hour_factor(df_peak: pd.DataFrame):\n",
    "    \"\"\"Returns the NETWORK peak hour factor for a given df_peak dataframe\"\"\"\n",
    "    fifteen_min_peaks = list(df_peak[\"total_15_min\"])\n",
    "    hourlymax = df_peak[\"total_hourly\"].iat[-1]\n",
    "    peak_hour_factor = hourlymax / (4 * max(fifteen_min_peaks))\n",
    "    return peak_hour_factor\n",
    "\n",
    "def write_summary_file(\n",
    "    input_folder: Union[Path, str],\n",
    "    output_folder: Union[Path, str] = None,\n",
    "    geocode_helper: str = None,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Create a new ``.xlsx`` summary file.\n",
    "\n",
    "    This file has two tabs:\n",
    "        - ``Summary`` contains a single line-item for each TMC\n",
    "        - ``Detail`` has 4 line-items per TMC:\n",
    "            - AM Peak Hour Total\n",
    "            - AM Peak Hour Percent Heavy Vehicles\n",
    "            - PM Peak Hour Total\n",
    "            - PM Peak Hour Percent Heavy Vehicles\n",
    "\n",
    "    TODO: review this format. Maybe 4 tabs instead of  4 rows?\n",
    "\n",
    "    Outputs a ZIP file with the Excel file and optional geojson file.\n",
    "\n",
    "    :param input_folder: folder where TMC data is stored\n",
    "    :type input_folder: Path\n",
    "    :param output_folder: folder where output ``.xlsx`` file will be stored\n",
    "    :type output_folder: Path, optional\n",
    "    :param geocode_helper: text that gets appended to the location\n",
    "                           name to assist with geocoding precision.\n",
    "    :type geocode_helper: str, optional but HIGHLY recommended!\n",
    "    :return: filepath of the new summary ZIP file\n",
    "    :rtype: Path\n",
    "    \"\"\"\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    metadata = []\n",
    "    detailed_data = []\n",
    "\n",
    "    # these two lists exist to add the peak hours, in seconds, so they can be averaged for the network later\n",
    "    am_peak_hour_list = []\n",
    "    pm_peak_hour_list = []\n",
    "\n",
    "    # created specifically to grab the actual datetime data for later use in the get_network_peak_hour function\n",
    "    am_peak_hour_times = []\n",
    "    pm_peak_hour_times = []\n",
    "\n",
    "    input_folder = Path(input_folder)\n",
    "\n",
    "    # Use the specified output folder\n",
    "    if output_folder:\n",
    "        output_folder = Path(output_folder)\n",
    "    # If none is specified, write to the input folder\n",
    "    else:\n",
    "        output_folder = Path(input_folder)\n",
    "\n",
    "    now_txt_1 = start_time.strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    now_txt_2 = start_time.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "\n",
    "    output_xlsx_filepath = output_folder / (\"TMC Summary \" + now_txt_1 + \".xlsx\")\n",
    "    output_geojson_filepath = output_folder / (\n",
    "        \"tmc_locations_\" + now_txt_2 + \".geojson\"\n",
    "    )\n",
    "    output_zip_file = output_folder / (\"tmc_summary_\" + now_txt_2 + \".zip\")\n",
    "\n",
    "    all_tmcs = []\n",
    "\n",
    "    # Extract dataframes from each file, put into appropriate list\n",
    "    for file in files_to_process(input_folder):\n",
    "        tmc = TMC_File(file)\n",
    "\n",
    "        # Single-row metadata DF\n",
    "        metadata.append(tmc.df_meta)\n",
    "\n",
    "        # For each cut listed below, get single-row DF\n",
    "        # -> (am_total, am_heavy_pct, pm_total, pm_heavy_pct)\n",
    "\n",
    "        for timeperiod in [\"am\", \"pm\"]:\n",
    "            meta_data_peak = list(tmc.df_meta.loc[:, f\"{timeperiod}_peak_raw\"])\n",
    "            time = meta_data_peak[0][0].to_pydatetime()\n",
    "            seconds = (time.hour * 60 + time.minute) * 60 + time.second\n",
    "            if timeperiod == \"am\":\n",
    "                am_peak_hour_list.append(seconds)\n",
    "                am_peak_hour_times.append(time)\n",
    "            elif timeperiod == \"pm\":\n",
    "                pm_peak_hour_list.append(seconds)\n",
    "                pm_peak_hour_times.append(time)\n",
    "            else:\n",
    "                print(\"Not a valid time period\")\n",
    "\n",
    "            for dtype in [\"total\", \"heavy_pct\"]:\n",
    "                identifier = f\"{timeperiod}_{dtype}\"\n",
    "\n",
    "                # Grab the appropriate dataframe\n",
    "                df = tmc.peak_data[identifier]\n",
    "\n",
    "                # Insert data into extra columns up front\n",
    "                df.insert(\n",
    "                    0, \"peak_hour_factor\", tmc.meta[f\"{timeperiod}_peak_hour_factor\"]\n",
    "                )\n",
    "                df.insert(0, \"time\", tmc.meta[f\"{timeperiod}_peak\"])\n",
    "                df.insert(0, \"period\", timeperiod)\n",
    "                df.insert(0, \"dtype\", dtype)\n",
    "                df.insert(0, \"location_id\", tmc.location_id)\n",
    "                df.insert(0, \"location_name\", tmc.meta[\"location_name\"])\n",
    "\n",
    "                detailed_data.append(df)\n",
    "\n",
    "        all_tmcs.append(tmc)\n",
    "\n",
    "    # Merge each list of dataframes into its own combined dataframe\n",
    "    df_meta = pd.concat(metadata)\n",
    "    df_meta[\"location_id\"] = df_meta[\"location_id\"].astype(int)\n",
    "    df_meta = df_meta.sort_values(\"location_id\", ascending=True)\n",
    "\n",
    "    df_detail = pd.concat(detailed_data)\n",
    "    df_detail[\"location_id\"] = df_detail[\"location_id\"].astype(int)\n",
    "    df_detail = df_detail.sort_values(\"location_id\", ascending=True)\n",
    "\n",
    "    # Add network peak hour in a nice format\n",
    "    am_peak_hr_seconds = statistics.median(am_peak_hour_list)\n",
    "    am_end = am_peak_hr_seconds + 3600\n",
    "    pm_peak_hr_seconds = statistics.median(pm_peak_hour_list)\n",
    "    pm_end = pm_peak_hr_seconds + 3600\n",
    "\n",
    "    am_network_peak_hour = str(timedelta(seconds=am_peak_hr_seconds))\n",
    "    am_network_end = str(timedelta(seconds=am_end))\n",
    "    pm_network_peak_hour = str(timedelta(seconds=pm_peak_hr_seconds))\n",
    "    pm_network_end = str(timedelta(seconds=pm_end))\n",
    "\n",
    "    # Add network peak hour TIMES in a usable format for get_network_peak function. specifically returns times, not timedeltas or seconds\n",
    "    am_network_peak_start_time = am_peak_hour_times[len(am_peak_hour_times) // 2]\n",
    "    am_network_peak_end_time = am_network_peak_start_time + timedelta(hours=1)\n",
    "    pm_network_peak_start_time = pm_peak_hour_times[len(pm_peak_hour_times) // 2]\n",
    "    pm_network_peak_end_time = pm_network_peak_start_time + timedelta(hours=1)\n",
    "\n",
    "    df_meta = df_meta.drop(columns=[\"am_peak_raw\", \"pm_peak_raw\"])\n",
    "    df_meta.insert(\n",
    "        4, \"pm_network_peak\", (f\"{pm_network_peak_hour} to {pm_network_end}\")\n",
    "    )\n",
    "    df_meta.insert(\n",
    "        4, \"am_network_peak\", (f\"{am_network_peak_hour} to {am_network_end}\")\n",
    "    )\n",
    "    df_meta = df_meta.drop(columns=[\"am_peak_hour_factor\", \"pm_peak_hour_factor\"])\n",
    "\n",
    "    # Clear data from detail, fill in by looking up network peak hour and peak hour factor\n",
    "    df_meta = df_meta.set_index(\"location_id\")\n",
    "    df_detail = df_detail.reset_index(drop=True)\n",
    "\n",
    "    tmc_dfs = {\n",
    "        \"am_dict\": {},\n",
    "        \"pm_dict\": {},\n",
    "    }  # Makes a dict of one-row dataframes that contains the volumes using the NETWORK peak hour instead of intersection peak hour\n",
    "    heavy_vehicle_dfs = {\n",
    "        \"am_dict\": {},\n",
    "        \"pm_dict\": {},\n",
    "    }  # Same as above but for percentages, not volumes\n",
    "    peak_hr_factors = {\n",
    "        \"am_dict\": {},\n",
    "        \"pm_dict\": {},\n",
    "    }  # Same as above but for peak hour factors\n",
    "    car_dfs = {\n",
    "        \"am_dict\": {},\n",
    "        \"pm_dict\": {},\n",
    "    }  # Same as above but for peds in xwalk (which lives in cars tab)\n",
    "    heavy_vehicle_for_bikes_dfs = {\n",
    "        \"am_dict\": {},\n",
    "        \"pm_dict\": {},\n",
    "    }  # Same as above but for bikes in xwalk (which lives in heavy vehicles tab)\n",
    "\n",
    "\n",
    "\n",
    "    for tmc in all_tmcs:\n",
    "        tmc_id = tmc.location_id\n",
    "        tmc_id = int(tmc_id)\n",
    "        \n",
    "        am_df = get_network_peak_hour_df(\n",
    "            tmc.df_total,\n",
    "            am_network_peak_start_time.time(),\n",
    "            am_network_peak_end_time.time(),\n",
    "        )\n",
    "        pm_df = get_network_peak_hour_df(\n",
    "            tmc.df_total,\n",
    "            pm_network_peak_start_time.time(),\n",
    "            pm_network_peak_end_time.time(),\n",
    "        )\n",
    "\n",
    "        am_cars_df = get_network_peak_hour_df(\n",
    "            tmc.df_cars, \n",
    "            am_network_peak_start_time.time(),\n",
    "            am_network_peak_end_time.time(),\n",
    "        )\n",
    "\n",
    "        pm_cars_df = get_network_peak_hour_df(\n",
    "            tmc.df_cars, \n",
    "            pm_network_peak_start_time.time(),\n",
    "            pm_network_peak_end_time.time(),\n",
    "        )\n",
    "        am_heavy_df = get_network_peak_hour_df(\n",
    "            tmc.df_heavy, \n",
    "            am_network_peak_start_time.time(),\n",
    "            am_network_peak_end_time.time(),\n",
    "        )\n",
    "\n",
    "        pm_heavy_df = get_network_peak_hour_df(\n",
    "            tmc.df_heavy, \n",
    "            pm_network_peak_start_time.time(),\n",
    "            pm_network_peak_end_time.time(),\n",
    "        )\n",
    "\n",
    "        tmc_dfs[\"am_dict\"][tmc_id] = am_df  # nests am_df into tmc_dfs dict\n",
    "        tmc_dfs[\"pm_dict\"][tmc_id] = pm_df\n",
    "\n",
    "        am_hv_pc = df_network_peak_hour_heavy_pct(\n",
    "            am_network_peak_start_time.time(),\n",
    "            am_network_peak_end_time.time(),\n",
    "            tmc.df_total,\n",
    "            tmc.df_cars,\n",
    "        )\n",
    "        pm_hv_pc = df_network_peak_hour_heavy_pct(\n",
    "            pm_network_peak_start_time.time(),\n",
    "            pm_network_peak_end_time.time(),\n",
    "            tmc.df_total,\n",
    "            tmc.df_cars,\n",
    "        )\n",
    "        heavy_vehicle_dfs[\"am_dict\"][\n",
    "            tmc_id\n",
    "        ] = am_hv_pc  # nests heavy vehicle percentages into hv dict\n",
    "        heavy_vehicle_dfs[\"pm_dict\"][tmc_id] = pm_hv_pc\n",
    "\n",
    "        am_network_peak_hour_factor = network_peak_hour_factor(\n",
    "            get_df_peak(\n",
    "                tmc.df_total,\n",
    "                am_network_peak_start_time.time(),\n",
    "                am_network_peak_end_time.time(),\n",
    "            )\n",
    "        )\n",
    "        pm_network_peak_hour_factor = network_peak_hour_factor(\n",
    "            get_df_peak(\n",
    "                tmc.df_total,\n",
    "                pm_network_peak_start_time.time(),\n",
    "                pm_network_peak_end_time.time(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # nests dfs into peak_hr_factors dict\n",
    "        peak_hr_factors[\"am_dict\"][tmc_id] = am_network_peak_hour_factor  \n",
    "        peak_hr_factors[\"pm_dict\"][tmc_id] = pm_network_peak_hour_factor\n",
    "\n",
    "        # drop car and heavy vehicle one line dfs into dicts\n",
    "        car_dfs[\"am_dict\"][tmc_id] = am_cars_df\n",
    "        car_dfs[\"pm_dict\"][tmc_id] = pm_cars_df\n",
    "        heavy_vehicle_for_bikes_dfs[\"am_dict\"][tmc_id] = am_heavy_df\n",
    "        heavy_vehicle_for_bikes_dfs[\"pm_dict\"][tmc_id] = pm_heavy_df\n",
    "\n",
    "\n",
    "    df_detail.loc[df_detail[\"period\"] == \"am\", \"time\"] = df_meta.at[\n",
    "        1, \"am_network_peak\"\n",
    "    ]\n",
    "    df_detail.loc[df_detail[\"period\"] == \"pm\", \"time\"] = df_meta.at[\n",
    "        1, \"pm_network_peak\"\n",
    "    ]\n",
    "\n",
    "    def update_time_period_totals(key, time: str):\n",
    "        condition = (\n",
    "            (df_detail[\"period\"] == f\"{time}\")\n",
    "            & (df_detail[\"dtype\"] == \"total\")\n",
    "            & (df_detail[\"location_id\"] == key)\n",
    "        )\n",
    "        df_detail.loc[condition, \"EB U\":\"total_15_min\"] = tmc_dfs[f\"{time}_dict\"][\n",
    "            key\n",
    "        ].values\n",
    "\n",
    "    def update_time_period_heavy_vehicles(key, time: str):\n",
    "        condition = (\n",
    "            (df_detail[\"period\"] == f\"{time}\")\n",
    "            & (df_detail[\"dtype\"] == \"heavy_pct\")\n",
    "            & (df_detail[\"location_id\"] == key)\n",
    "        )\n",
    "        df_detail.loc[condition, \"EB U\":\"total_15_min\"] = heavy_vehicle_dfs[\n",
    "            f\"{time}_dict\"\n",
    "        ][key].values\n",
    "\n",
    "    def update_peak_hour_factors(key, time: str):\n",
    "        condition = (\n",
    "            (df_detail[\"period\"] == f\"{time}\")\n",
    "            & (df_detail[\"location_id\"] == key)\n",
    "            & (df_detail[\"dtype\"] == \"total\")\n",
    "        )\n",
    "        condition2 = (\n",
    "            (df_detail[\"period\"] == f\"{time}\")\n",
    "            & (df_detail[\"location_id\"] == key)\n",
    "            & (df_detail[\"dtype\"] == \"heavy_pct\")\n",
    "        )\n",
    "        df_detail.loc[condition, \"peak_hour_factor\"] = peak_hr_factors[f\"{time}_dict\"][\n",
    "            key\n",
    "        ]\n",
    "        df_detail.loc[condition2, \"peak_hour_factor\"] = 0\n",
    "\n",
    "    def update_bike_ped_info(key, time: str):\n",
    "        \"\"\"grabs correct bike/ped info from the cars and heavy vehicles sheets, respectively\"\"\"\n",
    "        condition = (\n",
    "            (df_detail[\"period\"] == f\"{time}\")\n",
    "            & (df_detail[\"location_id\"] == key)\n",
    "            & (df_detail[\"dtype\"] == \"total\")\n",
    "        )\n",
    "        condition2 = (\n",
    "            (df_detail[\"period\"] == f\"{time}\")\n",
    "            & (df_detail[\"location_id\"] == key)\n",
    "            & (df_detail[\"dtype\"] == \"heavy_pct\")\n",
    "        )        \n",
    "        directions = [\"EB\", \"WB\", \"NB\", \"SB\"]\n",
    "        for direction in directions:\n",
    "            df_detail.loc[condition, f\"{direction} Bikes Xwalk\"] = heavy_vehicle_for_bikes_dfs[f\"{time}_dict\"][key][f\"{direction} Bikes Xwalk\"][0]\n",
    "            df_detail.loc[condition2, f\"{direction} Bikes Xwalk\"] = 0\n",
    "        \n",
    "        for direction in directions:\n",
    "            df_detail.loc[condition, f\"{direction} Peds Xwalk\"] = car_dfs[f\"{time}_dict\"][key][f\"{direction} Peds Xwalk\"][0]\n",
    "            df_detail.loc[condition2, f\"{direction} Peds Xwalk\"] = 0\n",
    "\n",
    "\n",
    "    for key in tmc_dfs[\"am_dict\"]:\n",
    "        update_time_period_totals(key, \"am\")\n",
    "        update_time_period_heavy_vehicles(key, \"am\")\n",
    "        update_peak_hour_factors(key, \"am\")\n",
    "        update_bike_ped_info(key, \"am\")\n",
    "        \n",
    "    for key in tmc_dfs[\"pm_dict\"]:\n",
    "        update_time_period_totals(key, \"pm\")\n",
    "        update_time_period_heavy_vehicles(key, \"pm\")\n",
    "        update_peak_hour_factors(key, \"pm\")\n",
    "        update_bike_ped_info(key, \"pm\")\n",
    "\n",
    "    df_detail = df_detail.rename(columns={\"EB Xwalk Xings\": \"EB Bikes Xwalk\", \"WB Xwalk Xings\": \"WB Bikes Xwalk\", \"NB Xwalk Xings\": \"NB Bikes Xwalk\", \"SB Xwalk Xings\": \"SB Bikes Xwalk\"}, errors=\"raise\")\n",
    "    reordered_cols = ['location_name',\n",
    " 'location_id',\n",
    " 'dtype',\n",
    " 'period',\n",
    " 'time',\n",
    " 'peak_hour_factor',\n",
    " 'EB U',\n",
    " 'EB Left',\n",
    " 'EB Thru',\n",
    " 'EB Right',\n",
    " 'EB Peds Xwalk',\n",
    " 'EB Bikes Xwalk',\n",
    " 'WB U',\n",
    " 'WB Left',\n",
    " 'WB Thru',\n",
    " 'WB Right',\n",
    " 'WB Peds Xwalk',\n",
    " 'WB Bikes Xwalk',\n",
    " 'NB U',\n",
    " 'NB Left',\n",
    " 'NB Thru',\n",
    " 'NB Right',\n",
    " 'NB Peds Xwalk',\n",
    " 'NB Bikes Xwalk',\n",
    " 'SB U',\n",
    " 'SB Left',\n",
    " 'SB Thru',\n",
    " 'SB Right',\n",
    " 'SB Peds Xwalk',\n",
    " 'SB Bikes Xwalk',\n",
    " 'total_15_min'\n",
    " ]\n",
    "    # have to do this after reorder/renames \n",
    "    for key in tmc_dfs[\"am_dict\"]:\n",
    "        update_bike_ped_info(key, \"am\")\n",
    "        \n",
    "    for key in tmc_dfs[\"pm_dict\"]:\n",
    "        update_bike_ped_info(key, \"pm\")\n",
    "\n",
    "    df_detail = df_detail[reordered_cols] \n",
    "    df_detail = df_detail.rename(columns={\"total_15_min\": \"total_60_min\"})\n",
    "\n",
    "    #removes duplicate {direction} bike columns (can't figure out where they came from, but they're the exact same)\n",
    "    df_detail = df_detail.loc[:,~df_detail.columns.duplicated()].copy()\n",
    "    return df_detail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 1_Callowhill-St-13th-St.xls\n",
      "Reading 2_Callowhill-St-12th-St.xls\n",
      "Reading 3_Callowhill-St-11th-St.xls\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_name</th>\n",
       "      <th>location_id</th>\n",
       "      <th>dtype</th>\n",
       "      <th>period</th>\n",
       "      <th>time</th>\n",
       "      <th>peak_hour_factor</th>\n",
       "      <th>EB U</th>\n",
       "      <th>EB Left</th>\n",
       "      <th>EB Thru</th>\n",
       "      <th>EB Right</th>\n",
       "      <th>...</th>\n",
       "      <th>NB Right</th>\n",
       "      <th>NB Peds Xwalk</th>\n",
       "      <th>NB Bikes Xwalk</th>\n",
       "      <th>SB U</th>\n",
       "      <th>SB Left</th>\n",
       "      <th>SB Thru</th>\n",
       "      <th>SB Right</th>\n",
       "      <th>SB Peds Xwalk</th>\n",
       "      <th>SB Bikes Xwalk</th>\n",
       "      <th>total_60_min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>162865 - Callowhill St &amp;13th St</td>\n",
       "      <td>1</td>\n",
       "      <td>total</td>\n",
       "      <td>am</td>\n",
       "      <td>8:15:00 to 9:15:00</td>\n",
       "      <td>0.957880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>705.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162865 - Callowhill St &amp;13th St</td>\n",
       "      <td>1</td>\n",
       "      <td>heavy_pct</td>\n",
       "      <td>am</td>\n",
       "      <td>8:15:00 to 9:15:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.127660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162865 - Callowhill St &amp;13th St</td>\n",
       "      <td>1</td>\n",
       "      <td>total</td>\n",
       "      <td>pm</td>\n",
       "      <td>17:00:00 to 18:00:00</td>\n",
       "      <td>0.900524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>688.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162865 - Callowhill St &amp;13th St</td>\n",
       "      <td>1</td>\n",
       "      <td>heavy_pct</td>\n",
       "      <td>pm</td>\n",
       "      <td>17:00:00 to 18:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>162866 - Callowhill St &amp; 12th St</td>\n",
       "      <td>2</td>\n",
       "      <td>total</td>\n",
       "      <td>am</td>\n",
       "      <td>8:15:00 to 9:15:00</td>\n",
       "      <td>0.922826</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>849.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>162866 - Callowhill St &amp; 12th St</td>\n",
       "      <td>2</td>\n",
       "      <td>heavy_pct</td>\n",
       "      <td>am</td>\n",
       "      <td>8:15:00 to 9:15:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.906250</td>\n",
       "      <td>5.769231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.182568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>162866 - Callowhill St &amp; 12th St</td>\n",
       "      <td>2</td>\n",
       "      <td>total</td>\n",
       "      <td>pm</td>\n",
       "      <td>17:00:00 to 18:00:00</td>\n",
       "      <td>0.954060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>893.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>162866 - Callowhill St &amp; 12th St</td>\n",
       "      <td>2</td>\n",
       "      <td>heavy_pct</td>\n",
       "      <td>pm</td>\n",
       "      <td>17:00:00 to 18:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.065134</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.359462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>162867 - CallowhillSt &amp; 11th St</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>am</td>\n",
       "      <td>8:15:00 to 9:15:00</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>162867 - CallowhillSt &amp; 11th St</td>\n",
       "      <td>3</td>\n",
       "      <td>heavy_pct</td>\n",
       "      <td>am</td>\n",
       "      <td>8:15:00 to 9:15:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.701835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>162867 - CallowhillSt &amp; 11th St</td>\n",
       "      <td>3</td>\n",
       "      <td>total</td>\n",
       "      <td>pm</td>\n",
       "      <td>17:00:00 to 18:00:00</td>\n",
       "      <td>0.937764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>162867 - CallowhillSt &amp; 11th St</td>\n",
       "      <td>3</td>\n",
       "      <td>heavy_pct</td>\n",
       "      <td>pm</td>\n",
       "      <td>17:00:00 to 18:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.812148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       location_name  location_id      dtype period  \\\n",
       "0    162865 - Callowhill St &13th St            1      total     am   \n",
       "1    162865 - Callowhill St &13th St            1  heavy_pct     am   \n",
       "2    162865 - Callowhill St &13th St            1      total     pm   \n",
       "3    162865 - Callowhill St &13th St            1  heavy_pct     pm   \n",
       "4   162866 - Callowhill St & 12th St            2      total     am   \n",
       "5   162866 - Callowhill St & 12th St            2  heavy_pct     am   \n",
       "6   162866 - Callowhill St & 12th St            2      total     pm   \n",
       "7   162866 - Callowhill St & 12th St            2  heavy_pct     pm   \n",
       "8    162867 - CallowhillSt & 11th St            3      total     am   \n",
       "9    162867 - CallowhillSt & 11th St            3  heavy_pct     am   \n",
       "10   162867 - CallowhillSt & 11th St            3      total     pm   \n",
       "11   162867 - CallowhillSt & 11th St            3  heavy_pct     pm   \n",
       "\n",
       "                    time  peak_hour_factor  EB U  EB Left  EB Thru  EB Right  \\\n",
       "0     8:15:00 to 9:15:00          0.957880   0.0      0.0      0.0       0.0   \n",
       "1     8:15:00 to 9:15:00          0.000000   NaN      NaN      NaN       NaN   \n",
       "2   17:00:00 to 18:00:00          0.900524   0.0      1.0      0.0       0.0   \n",
       "3   17:00:00 to 18:00:00          0.000000   NaN      0.0      NaN       NaN   \n",
       "4     8:15:00 to 9:15:00          0.922826   0.0      0.0      0.0       0.0   \n",
       "5     8:15:00 to 9:15:00          0.000000   NaN      NaN      NaN       NaN   \n",
       "6   17:00:00 to 18:00:00          0.954060   0.0      0.0      0.0       0.0   \n",
       "7   17:00:00 to 18:00:00          0.000000   NaN      NaN      NaN       NaN   \n",
       "8     8:15:00 to 9:15:00          0.908333   0.0      0.0      0.0       0.0   \n",
       "9     8:15:00 to 9:15:00          0.000000   NaN      NaN      NaN       NaN   \n",
       "10  17:00:00 to 18:00:00          0.937764   0.0      0.0      0.0       0.0   \n",
       "11  17:00:00 to 18:00:00          0.000000   NaN      NaN      NaN       NaN   \n",
       "\n",
       "    ...  NB Right  NB Peds Xwalk  NB Bikes Xwalk  SB U  SB Left     SB Thru  \\\n",
       "0   ...       0.0           19.0             0.0   0.0      0.0    0.000000   \n",
       "1   ...       NaN            0.0             0.0   NaN      NaN         NaN   \n",
       "2   ...       0.0           18.0             1.0   0.0      0.0    0.000000   \n",
       "3   ...       NaN            0.0             0.0   NaN      NaN         NaN   \n",
       "4   ...       0.0           20.0             2.0   0.0      0.0  256.000000   \n",
       "5   ...       NaN            0.0             0.0   NaN      NaN    3.906250   \n",
       "6   ...       0.0           28.0             4.0   0.0      0.0  261.000000   \n",
       "7   ...       NaN            0.0             0.0   NaN      NaN    3.065134   \n",
       "8   ...       0.0           13.0             1.0   0.0      0.0    0.000000   \n",
       "9   ...       NaN            0.0             0.0   NaN      NaN         NaN   \n",
       "10  ...       0.0           36.0             1.0   0.0      0.0    0.000000   \n",
       "11  ...       NaN            0.0             0.0   NaN      NaN         NaN   \n",
       "\n",
       "     SB Right  SB Peds Xwalk  SB Bikes Xwalk  total_60_min  \n",
       "0    0.000000           39.0             2.0    705.000000  \n",
       "1         NaN            0.0             0.0      2.127660  \n",
       "2    0.000000           24.0             1.0    688.000000  \n",
       "3         NaN            0.0             0.0      1.598837  \n",
       "4   52.000000           11.0             0.0    849.000000  \n",
       "5    5.769231            0.0             0.0      5.182568  \n",
       "6   40.000000           14.0             3.0    893.000000  \n",
       "7    2.500000            0.0             0.0      3.359462  \n",
       "8    0.000000            8.0             1.0    872.000000  \n",
       "9         NaN            0.0             0.0      4.701835  \n",
       "10   0.000000            6.0             1.0    889.000000  \n",
       "11        NaN            0.0             0.0      2.812148  \n",
       "\n",
       "[12 rows x 31 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_summary_file('/mnt/g/My Drive/TMC2/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tmc_summarizer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c8f58f42a5efc4c93fa2b656e0d4587a7fc0ed98038db235e73ba452edb6582e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
